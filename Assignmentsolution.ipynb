{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK2kHz1zy7yK",
        "colab_type": "text"
      },
      "source": [
        "Implementing an YOLO Algorithm is highly complex and very time consuming. In this assignment, I will walk you through the process. \n",
        "The data set I used for the assignment is in this [link ](https://storage.googleapis.com/open_source_datasets/ShelfImages.tar.gz)\n",
        "The data set is split into two parts namely train and test\n",
        "\n",
        "This dataset contains only images but not the annotations\n",
        "Annotations to this file are found in a text file in github. The link to the github repository consisting annotations.txt file  is [here ](https://github.com/gulvarol/grocerydataset/)\n",
        "\n",
        "In any code cell, Uncomment the Print commands to Understand the output. And the data flow. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcOJL2DSm3Aw",
        "colab_type": "text"
      },
      "source": [
        "# **For Data Preperation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHcd2nJrxGoi",
        "colab_type": "text"
      },
      "source": [
        "It is very complicated in google colab to download or upload files. This would be helpful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa9s3z8EKE4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining Functions that are useful in  future to download , Upload and print files.\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()\n",
        "\n",
        "# use this to upload files\n",
        "def upload():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload() \n",
        "  for name, data in uploaded.items():\n",
        "    with open(name, 'wb') as f:\n",
        "      f.write(data)\n",
        "      print ('saved file', name)\n",
        "\n",
        "# use this to download a file  \n",
        "def download(path):\n",
        "  from google.colab import files\n",
        "  files.download(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpLVpzKnn39j",
        "colab_type": "text"
      },
      "source": [
        "**Downloading Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYhDXd3OlrGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this code sets the data up, the extracted file shelfimages can probably be shared as shelfimages1 ev\n",
        "\n",
        "!git clone https://github.com/gulvarol/grocerydataset/ #cloning git repository of meta data and description\n",
        "\n",
        "#!wget https://github.com/gulvarol/grocerydataset/releases/download/1.0/GroceryDataset_part1.tar.gz #downloading part1 data\n",
        "#!wget https://github.com/gulvarol/grocerydataset/releases/download/1.0/GroceryDataset_part2.tar.gz #downloading part2 data\n",
        "#!tar --gunzip --extract --verbose --file=GroceryDataset_part1.tar.gz #extracting the tar files into a folder\n",
        "#!tar --gunzip --extract --verbose --file=GroceryDataset_part2.tar.gz \n",
        "\n",
        "!wget https://storage.googleapis.com/open_source_datasets/ShelfImages.tar.gz #downloads add on provided by the assignment\n",
        " \n",
        "!tar --gunzip --extract --verbose --file=ShelfImages.tar.gz #extracts add ondata tar folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5252E1vtmm7",
        "colab_type": "text"
      },
      "source": [
        "**Data Preperation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgC7IQuyutmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#changing working directory \n",
        "%cd grocerydataset/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I88JxrIaEgmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reading the data from an annotation file to a dictionary with file names as key and the data of the objects in it as a dict (list ) attached to the key\n",
        "\n",
        "\n",
        "#open a file into a file variable f \n",
        "f = open('annotation.txt') \n",
        "\n",
        "#Loads the entire content into a variable l ( A large string ). Uncomment print(l) to find more\n",
        "l = f.read()\n",
        "#print(l)\n",
        "\n",
        "#The following command Splits the big text and writes each line into a fresh string. And compiles the strings into an array of strings uncomment to witness \n",
        "k = l.splitlines()\n",
        "m = list(k)\n",
        "#print(m)\n",
        "\n",
        "#creating an empty dict \n",
        "Dictionarydata = dict()\n",
        "\n",
        "#Iterating over list of strings. Each i refers to one image \n",
        "for i in m :\n",
        "  #splits each string into various little strings whenever a space is encountered\n",
        "  p = i.split()\n",
        "  #the first string in that contains the name of image. So we create a dict with name of the image as key  and write the rest of the data to that key as values uncomment printbelow to find it out\n",
        "  Dictionarydata[p[0]]= p[1:]\n",
        "  #print(Dictionarydata)\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOFwtUA4MsTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#taking the list of files in test and train directories and storing them as a list of strings. \n",
        "#os.lisdir() Function lists all the available files in the current working directory into a list of strings. Uncomment print to understand the output\n",
        "import os \n",
        "%cd ..\n",
        "%cd 'ShelfImages/test'\n",
        "testlist = os.listdir()\n",
        "#print(testlist)\n",
        "%cd ..\n",
        "%cd train\n",
        "trainlist = os.listdir()\n",
        "#print(trainlist)\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwd27TVyvitI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "So, as we described in the Document, We have a list of all the train and test image names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TJymrBTO7PA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#yolo usually asks for text files corresponding to each image\n",
        "#In order to create names for text files this would be very handy \n",
        "\n",
        "\n",
        "#creating two empty lists\n",
        "trainlistnamestextfiles = list() \n",
        "testlistnamestextfiles = list()\n",
        "\n",
        "#iterating over the Previously obtained lists which contains the \n",
        "for i in trainlist :\n",
        "  #the last three letters of image names are jpg when we remove them and name txt , we have the names of the corresponding text files uncomment print function in the end to find out how they unveil \n",
        "  trainlistnamestextfiles.append(str(i[:-3])+'txt')\n",
        "for i in testlist :\n",
        "  testlistnamestextfiles.append(str(i[:-3])+'txt')\n",
        "\n",
        "#print(trainlistnamestextfiles)\n",
        "#print(testlistnamestextfiles)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYJNo5ao1Yhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2 \n",
        "%cd \n",
        "%cd ..\n",
        "%cd /content/ShelfImages/train\n",
        "\n",
        "#Now we are iterating over the trainlist and testlist Lists so that we can do data processing\n",
        "\n",
        "for i in range(len(trainlist)) :\n",
        "\n",
        "  #as we know that the dictionarydata contains the dict with images names as key and A long list of strings which are numbers as the value\n",
        "  arrayofsinglefile = Dictionarydata[trainlist[i]] \n",
        "  #print(arrayofsinglefile, '\\n')\n",
        "\n",
        "  # The First string of the list is the number of detections obtained in a particular image \n",
        "  countofdetectionsinparticularimage = arrayofsinglefile[0]\n",
        "  #print(countofdetectionsinparticularimage)\n",
        "  #print('\\n')\n",
        "\n",
        "  #The rest of the list is x, y , width , height , class repeated count number of times. so Now we reshape the list and write each object in a row and 5 columns containing , \n",
        "  array = np.array(arrayofsinglefile[1:],dtype = float).reshape(int(countofdetectionsinparticularimage),5)\n",
        "  \n",
        "  #now we need classes in the first column according to the format YOLO accepts. and all other colums should be moved right. So we use np.roll() \n",
        "  #This pushes 4 all the colums to one step right and brings the lost column to the first\n",
        "\n",
        "  array=np.roll(array, 1, axis=1)\n",
        "  #print(array, '\\n')\n",
        "\n",
        "  #as I said that the inputs of each files to YOLO should be floats\n",
        "  image = cv2.imread(trainlist[i])\n",
        "  height,width= image.shape[0],image.shape[1]\n",
        "  #print(height,width)\n",
        "  #print('\\n')\n",
        "  #print(len(array))\n",
        "  #print(array[:][:])\n",
        "  for j in range(int(countofdetectionsinparticularimage)):\n",
        "    for k in range(1,5):\n",
        "      #print(k)\n",
        "      if(k== 2):\n",
        "        array[j][k]=int(array[j][k])/height\n",
        "        #if array[j][k]>1:\n",
        "          #print('error2')\n",
        "          #print(array[j][k],height,width) # uncomment these if you find an error stating that , the values of weights either less than zero or greater than 1 \n",
        "      elif(k == 4):\n",
        "        array[j][k]=int(array[j][k])/height\n",
        "        #if array[j][k]>1: \n",
        "          #print('error4')\n",
        "          #print(array[j][k],height,width)\n",
        "      elif(k== 3):\n",
        "        array[j][k]=int(array[j][k])/width\n",
        "        #if array[j][k]>1:\n",
        "          #print('error3')\n",
        "          #print(array[j][k],height,width)\n",
        "      elif(k==1 ):\n",
        "        array[j][k]=int(array[j][k])/width\n",
        "        #if array[j][k]>1:\n",
        "          #print('error1')\n",
        "          #print(array[j][k],height,width)\n",
        "  #print(array, '\\n')\n",
        "\n",
        "\n",
        "\n",
        "  # thus we obtained an array that is exactly same as how each file should look \n",
        "  #opening the file and writing the array in the text file\n",
        "  \n",
        "  with open('{}'.format(trainlistnamestextfiles[i]), 'w') as f:\n",
        "    for x in range(int(countofdetectionsinparticularimage)):\n",
        "\n",
        "      for y in range(5):\n",
        "        if y == 0 :\n",
        "          f.write(str(0) + ' ')\n",
        "          #f.write(str(float(array[x][y])) + ' ') uncomment this for 11 objects training\n",
        "        else:\n",
        "          f.write(str(float(array[x][y])) + ' ')\n",
        "      f.write('\\n')      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ2iSzzy1YRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the comments are same as the above cell, just the folder changes. \n",
        "import numpy as np\n",
        "import cv2 \n",
        "%cd /content/ShelfImages/test\n",
        "\n",
        "for i in range(len(testlist)) :\n",
        "  arrayofsinglefile = Dictionarydata[testlist[i]]\n",
        "  #print(arrayofsinglefile, '\\n')\n",
        "  countofdetectionsinparticularimage = arrayofsinglefile[0]\n",
        "  #print(countofdetectionsinparticularimage)\n",
        "  #print('\\n')\n",
        "  array = np.array(arrayofsinglefile[1:],dtype = float).reshape(int(countofdetectionsinparticularimage),5)\n",
        "  # reshapethedata=array.reshape(int(countofdetectionsinparticularimage),5))\n",
        "  #To swap columns use the followng code  \n",
        "  #array[:,[0,4]]=array[:,[4,0]]\n",
        "  #To shift each column in an array use np.roll() in numpy\n",
        "  array=np.roll(array, 1, axis=1)\n",
        "  #print(array, '\\n')\n",
        "  image = cv2.imread(testlist[i])\n",
        "  height,width= image.shape[0],image.shape[1]\n",
        "  #print(height,width)\n",
        "  #print('\\n')\n",
        "  #print(len(array))\n",
        "  #print(array[:][:])\n",
        "  for j in range(int(countofdetectionsinparticularimage)):\n",
        "    for k in range(1,5):\n",
        "      #print(k)\n",
        "      if(k== 2):\n",
        "        array[j][k]=int(array[j][k])/height\n",
        "        #if array[j][k]>1:\n",
        "         # print('error2')\n",
        "         # print(array[j][k],height,width)\n",
        "      if(k == 4):\n",
        "        array[j][k]=int(array[j][k])/height\n",
        "        #if array[j][k]>1:\n",
        "          #print('error4')\n",
        "          #print(array[j][k],height,width)\n",
        "      if(k== 3):\n",
        "        array[j][k]=int(array[j][k])/width\n",
        "        #if array[j][k]>1:\n",
        "          #print('error3')\n",
        "          #print(array[j][k],height,width)\n",
        "      elif(k==1 ):\n",
        "        array[j][k]=int(array[j][k])/width\n",
        "        #if array[j][k]>1:\n",
        "          #print('error1')\n",
        "          #print(array[j][k],height,width)\n",
        "  #print(array, '\\n')\n",
        "  with open('{}'.format(testlistnamestextfiles[i]), 'w') as f:\n",
        "    for x in range(int(countofdetectionsinparticularimage)):\n",
        "\n",
        "      for y in range(5):\n",
        "        if y==0 :\n",
        "          f.write(str(0) + ' ')\n",
        "        else :\n",
        "          f.write(str(float(array[x][y])) + ' ')\n",
        "      f.write('\\n')      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y4chCbk5fhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Zipping the entire data folder and dowloading to avoid multiple data preperation. Please follow the steps below.\n",
        "!zip -r /content/obj.zip /content/ShelfImages/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pym6S-NL2FMR",
        "colab_type": "text"
      },
      "source": [
        "Here download the zip file into the folder and start performing the following operations ( you will be recquired  to run the 1,2,3 code blocks in your terminal before this)\n",
        "\n",
        "1) Extract the content of the obj.zip file. \n",
        "\n",
        "2) Navigate to the extracted zone , open content/darknet/shelfimages/train \n",
        "\n",
        "3) copy everything in the folder\n",
        "\n",
        "4) Navigate to root directory where darknet is cloned and made and further navigate to ./darknet/data/obj (create an obj empty file if necessary , also delete all the info in data folder before this step ) . in obj folder paste the image and text files. \n",
        "\n",
        "5) now in the terminal change the root directory to darknet \n",
        "\n",
        "6) clone the repo https://github.com/theAIGuysCode/YoloGenerateTrainingFile\n",
        "\n",
        "7) openn the below python file , find the word jpg and change it to JPG \n",
        "now in terminal type the following \n",
        "python YoloGenerateTrainingFile/generate_train.py\n",
        "\n",
        "8) this generates a text file train.txt. Copy the file and upload it into your google drive at yolov3 folder \n",
        "\n",
        "9) Now replace the contents in data/obj with contents from content/darknet/shelfimages/test \n",
        "\n",
        "10) repeat secondpart of  command 7\n",
        "\n",
        "11)rename the new txt file to test.txt , copy it and upload to drive at yolov3 folder\n",
        "\n",
        "12) open text editor write 11 object names , as you wish , one in a row , no spaces no tabs and save the file as obj.names\n",
        "\n",
        "13) open text editor and type as follows and save it as obj.data\n",
        "\n",
        "classes = 11\n",
        "\n",
        "train = data/train.txt\n",
        "\n",
        "valid = data/test.txt\n",
        "\n",
        "names = data/obj.names\n",
        "\n",
        "backup = /mydrive/yolov3/backup/\n",
        "\n",
        "14) upload objnames and obj.data to drive/yolov3 \n",
        "\n",
        "15) copy all the content from train and test folders and paste it in data/obj . compress the obj file to obj.zip and upload obj.zip to google drive/yolov3\n",
        "\n",
        "16) Download a Yolov3.cfg file from darknet/cfg into your desktop, Edit the following \n",
        "\n",
        "For 1 class training:\n",
        ">>\n",
        "1) Search for random flag and set random= 1\n",
        ">>\n",
        "2) search for batch and change batch = 64\n",
        ">>\n",
        "3) change line subdivisions to subdivisions=16\n",
        ">>\n",
        "4) change line max_batches to \n",
        "max_batches =6000\n",
        ">>\n",
        "5) change line steps = 4800,5400 \n",
        ">>\n",
        "6) find classes = 80 and change it to classes = 1\n",
        ">>\n",
        "7)change [filters=255] to filters=18 in the 3 [convolutional] before each [yolo] layer, keep in mind that it only has to be the last [convolutional] before each of the [yolo] layers.\n",
        ">>\n",
        "8) Save the config file as yolov3_custom.cfg\n",
        "\n",
        "for 11 clasess training : \n",
        ">>\n",
        "1) Search for random flag and set it to 1\n",
        ">>\n",
        "2) search for batch and change batch = 64\n",
        ">>\n",
        "3) change line subdivisions to subdivisions=16\n",
        ">>\n",
        "4) change line max_batches to \n",
        "max_batches = 22000\n",
        ">>\n",
        "5) Change line steps to steps = 17600, 19800\n",
        ">>\n",
        "6) Change line classes = 11\n",
        ">>\n",
        "7)change [filters=255] to filters= 48 in the 3 [convolutional] before each [yolo] layer, keep in mind that it only has to be the last [convolutional] before each of the [yolo] layers\n",
        ">>\n",
        "8) Save the config file as yolov3_custom.cfg\n",
        "\n",
        "14) Download the custiom weights from the following link [ download link](https://pjreddie.com/media/files/darknet53.conv.74)\n",
        "\n",
        "15 ) Add all the above to the YOLOV3 folder and upload it to google drive.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9cp1k80Tsmn",
        "colab_type": "text"
      },
      "source": [
        "Note : The anchor box ratio is just an approximation and should be tuned by observing the ratios of width and height from the dataset, Yolo original datasets usually perform well for this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hit1SoBfPhuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBoOHV7Yb1dX",
        "colab_type": "text"
      },
      "source": [
        "# **Thus the data preperation is done and we enter into training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phxppaJLKgxR",
        "colab_type": "text"
      },
      "source": [
        "Follow these steps to start training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zn3f_suKEnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mounting Google drive to colab\n",
        "%cd \n",
        "%cd ..\n",
        "%cd content/\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvxBMwvfXOD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# When we copy path of drive it has a space in it and is very irritating to use in many cases . Also generates some errors. So we create this link  \n",
        "#The link makes the system understand that both are same. \n",
        "%cd \n",
        "%cd ..\n",
        "!ln -s /content/gdrive/'My Drive/' /mydrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY-13bBg6m7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#changing directory to content . \n",
        "%cd \n",
        "%cd ..\n",
        "%cd content\n",
        "# clone darknet repo\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09QBJfw2LfCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use this code to check the cuda version installed in the GPU ( not much necessary)\n",
        "!nvcc --version "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE_mHX8zfpmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Making Darknet as the working directory.\n",
        "%cd darknet\n",
        "\n",
        "# since we are GPU powered we have to change some lines of the make file to enable GPU usage on darknet \n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3gRLmxDkmqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this makes the darknet . in windows it creates an exe software and in linux it makes \n",
        "!make"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GVWfCHXUvoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list files in yolov3 folder \n",
        "!ls /mydrive/yolov3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DbOWt8g9uSEJ",
        "colab": {}
      },
      "source": [
        "#Run this cell if your data is in obj folder in yolov3 folder in your drive. \n",
        "%cd \n",
        "%cd ..\n",
        "%cd content/gdrive/'My Drive'/yolov3\n",
        "!zip -r /content/obj.zip ./obj"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOhLgcI8pZnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unzip the zip file and its contents Into darknet/data folder.  the images and text files  should now be in /darknet/data/obj\n",
        "%cd \n",
        "%cd .. \n",
        "%cd content\n",
        "!unzip /content/obj.zip -d darknet/data "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFSxGlmTpeRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Copy config file Which is \n",
        "\n",
        "%cd \n",
        "%cd .. \n",
        "%cd content\n",
        "!cp /mydrive/yolov3/yolov3_custom.cfg darknet/cfg/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j8T5rHFplPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upload the obj.names and obj.data files and pre trained weights to cloud VM from Google Drive\n",
        "%cd \n",
        "%cd .. \n",
        "%cd content\n",
        "!cp /mydrive/yolov3/obj.names darknet/data\n",
        "!cp /mydrive/yolov3/obj.data  darknet/data\n",
        "!cp /mydrive/yolov3/darknet53.conv74  darknet #%cd darknet  #!wget https://pjreddie.com/media/files/darknet53.conv.74 would do the same if you dont want to download. \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xoTQ4akVYBG",
        "colab_type": "text"
      },
      "source": [
        "Training for the first time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReZHyEs1Vm5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This snippet of code starts training by making the \n",
        "%cd\n",
        "%cd ..\n",
        "%cd content/darknet\n",
        "!./darknet detector train data/obj.data cfg/yolov3_custom.cfg darknet53.conv.74 -dont_show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVHe59xnWW0o",
        "colab_type": "text"
      },
      "source": [
        "Training after 100 iterations, if it is stopped due to connectivity issues or you find your model inaccurate and you want to train more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgcfGJclWoyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This snipped obtains the last saved back up files and resumes training from there\n",
        "%cd \n",
        "%cd ..\n",
        "%cd content\n",
        "!cp /content/gdrive/'My Drive'/yolov3/yolov3_custom_last.weights /darknet\n",
        "%cd darknet/\n",
        "!./darknet detector train data/obj.data cfg/yolov3_custom.cfg yolov3_custom_last.weights -dont_show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNOSCbU8XNjH",
        "colab_type": "text"
      },
      "source": [
        "When to stop ? When the output is being printed , always observe the second number from the iteration number. It means avg_error. This should be near to zero. Try to stop when it is less than 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THmS5k7hWWEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT25-DjcX5eJ",
        "colab_type": "text"
      },
      "source": [
        "**Prediction , Validation and Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuOrRUyxYFxY",
        "colab_type": "text"
      },
      "source": [
        "to obtain a file with prediction  run the following command . Remember ? we gave valid = test.txt in obj.data. The following command reads those images and predicts over them. Then writes all the data to a file in darknet/results folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAo2yhDFYFRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./darknet detector valid data/obj.data cfg/yolov3_custom.cfg yolov3_custom_last.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqFEFLcQZJaY",
        "colab_type": "text"
      },
      "source": [
        "Observed the new file in results folder ? Lets analyse it and return the Json format as asked. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khnYGrt7VthH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd results/\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "res=[]\n",
        "img=[]\n",
        "imgprob=[]\n",
        "\n",
        "with open('comp4_det_test_Object.txt','r') as f:\n",
        "    for i in f:\n",
        "        res.append(i.split())\n",
        "        \n",
        "for i in range(len(res)):\n",
        "    img.append(res[i][0])\n",
        "    if(float(res[i][1]) > 0.3):\n",
        "        imgprob.append(1)\n",
        "    else:\n",
        "        imgprob.append(0)\n",
        "\n",
        "\n",
        "d = defaultdict(list)\n",
        "for k,v in zip(img, imgprob):\n",
        "    d[k].append(v)\n",
        " \n",
        "for i in d.keys():\n",
        "    lis=d[i]\n",
        "    d[i]=sum(lis)\n",
        "#print(d)\n",
        "\n",
        "import json\n",
        "print(json.dumps(d, sort_keys=True, indent=4))\n",
        "    \n",
        "with open('image2products.json', 'w') as fp:\n",
        "    json.dump(d, fp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMMmoLrUaSb7",
        "colab_type": "text"
      },
      "source": [
        "Download the json file and save it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO19JJmya27L",
        "colab_type": "text"
      },
      "source": [
        "Download the weights that are backed up in drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M0sygF9avZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd \n",
        "%cd ..\n",
        "%cd content\n",
        "!cp /content/gdrive/'My Drive'/yolov3/yolov3_custom_last.weights /darknet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qdVKYe_bJCY",
        "colab_type": "text"
      },
      "source": [
        "Run the following command to see the recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CAgnVpqaWnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./darknet detector recall data/obj.data cfg/yolov3_custom.cfg yolov3_custom_last.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wczdEe1ObPLk",
        "colab_type": "text"
      },
      "source": [
        "Run the following command to see the mAP "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx6SGimobUcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./darknet detector map data/obj.data cfg/yolov3_custom.cfg yolov3_custom_last.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN4GTsJNbfqH",
        "colab_type": "text"
      },
      "source": [
        "TO find the precision run the following command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhca0CRscAB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./darknet detector precision data/obj.data cfg/yolov3_custom.cfg yolov3_custom_last.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpras6OvcInt",
        "colab_type": "text"
      },
      "source": [
        "In case there is a need to calculate all the above metrics on you own and understand it . Please visit [ this link](https://towardsdatascience.com/evaluating-performance-of-an-object-detection-model-137a349c517b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuZvWqbycdF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Writing average , precision and recall in dict at IOU threshold 0.5\n",
        "dictionary = {\n",
        "    'mAP' : 0.8841,\n",
        "    'precision' : 0.95,\n",
        "    'recall' : 0.85\n",
        "}\n",
        "import json \n",
        "with open('metrics.json', 'w') as fp:\n",
        "    json.dump(dictionary, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTbwOnl6fFi7",
        "colab_type": "text"
      },
      "source": [
        "Look at my google drive folder incase you need any help [Folder](https://drive.google.com/drive/folders/1xtLAYfkVWLDh0aU2O5g_XaJrboRsAU7X?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emkBlrNLcHeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
